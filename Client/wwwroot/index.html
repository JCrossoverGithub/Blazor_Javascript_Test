<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
    <title>Blazor_Javascript_Test</title>
    <base href="/" />
    <link href="css/bootstrap/bootstrap.min.css" rel="stylesheet" />
    <link href="css/app.css" rel="stylesheet" />
    <link href="Blazor_Javascript_Test.Client.styles.css" rel="stylesheet" />
</head>

<body>
    <div id="app">Loading...</div>

    <div id="blazor-error-ui">
        An unhandled error has occurred.
        <a href="" class="reload">Reload</a>
        <a class="dismiss">ðŸ—™</a>
    </div>
    <script src="_framework/blazor.webassembly.js"></script>
    <script>
        window.MyJSMethods = {

            startRecording: function () {
                navigator.getUserMedia({ audio: true }, onSuccess, onError);
            },

            stopRecording: function (element) {
                stop.click();
            },

            startSpeechRecognition: function () {

                console.log("Start of startSpeechRecognition");

                try {
                    var SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                    var recognition = new SpeechRecognition();
                }
                catch (e) {
                    console.error(e);
                    $('.no-browser-support').show();
                    $('.app').hide();
                }

                recognition.onstart = function () {
                    console.log('Voice recognition activated. Try speaking into the microphone.');
                }

                recognition.onspeechend = function () {
                    console.log('You were quiet for a while so voice recognition turned itself off.');
                }

                recognition.onerror = function (event) {
                    if (event.error == 'no-speech') {
                        console.log('No speech was detected. Try again.');
                    };
                }

                recognition.onresult = function (event) {

                    // event is a SpeechRecognitionEvent object.
                    // It holds all the lines we have captured so far. 
                    // We only need the current one.
                    var current = event.resultIndex;

                    // Get a transcript of what was said.
                    var transcript = event.results[current][0].transcript;

                    // Add the current transcript to the contents of our Note.
                    //noteContent += transcript;
                    //noteTextarea.val(noteContent);
                    console.log(current);
                    console.log(transcript);
                    console.log(event);
                }

                recognition.continuous = true;

                console.log("recognition.start() Called");
                recognition.start();

                console.log("End of startSpeechRecognition");

            }
        }

        let onError = function (err) {
            console.log('The following error occurred: ' + err);
        };

        let onSuccess = function (stream) {
            let recorder;
            let context;
            let audio = document.querySelector('audio');    // Connection between the audio player in the HTML and the backend code.
            audio.srcObject = stream;                       // Connects the audio stream recieved from getUserMedia to the HTML audio player.
            console.log(stream.id);
            console.log(stream.active);
            console.log(stream.getAudioTracks());
            console.log(stream.getTracks());
        };




    </script>
</body>

</html>
